ğŸ“Œ Fine-Tuning Analysis Report: Google/Gemma-2B on Vicgalle/Alpaca-GPT4
Google Summer of Code (GSoC 2025) â€“ Contributions to Google DeepMind
ğŸ“… Date: 16-03-2025
ğŸ‘¤ Author: Rahul Lashkari + AI
ğŸ› ï¸ Objective: Fine-tune Gemma-2B on Vicgalle/Alpaca-GPT4 (Instruction Following) and analyze results for submission as Contributions to Google DeepMind (GSoC 2025)

ğŸ“Œ 1. Fine-Tuning Overview
Model: google/gemma-2b
Dataset: vicgalle/alpaca-gpt4
Fine-Tuning Type: Instruction Fine-Tuning
Epochs: 3
Cost: 10.025$
Learning Rate: 0.0002
LoRA Parameters:
LoRA Rank (lora_r): 8
LoRA Alpha (lora_alpha): 16
LoRA Dropout (lora_dropout): 0.1
LoRA Bias: "none"
Gradient Accumulation Steps: 1
Early Stopping Patience: 5
Data Split: 90% Train / 10% Validation

ğŸ“Œ 2. Key Training Metrics & Observations
ğŸ”¹ Training & Validation Loss Improvement
âœ… Train Loss Decrease: 59.42%
âœ… Validation Loss Decrease: 18.77%

ğŸ“‰ Interpretation:
The model significantly reduced training loss (59.42%), confirming that it successfully learned patterns from the Alpaca-GPT4 dataset.
Validation loss decreased by 18.77%, showing that the model retained generalization ability but may still benefit from additional fine-tuning.

ğŸ”¹ Learning Curve & Further Training Potential
ğŸ“ˆ Key Observations:
Loss continued decreasing steadily, meaning the model was still improving when training ended.
No signs of overfitting, as validation loss didn't spike in later epochs.
Possible Benefit of Extra Training: Running 1-2 more epochs could further enhance instruction-following quality.

ğŸ”¹ Model Performance on Token Accuracy
âœ… Final Mean Token Accuracy: ~75.13%
Started at: ~52.27% â†’ Reached: ~75.13%

Interpretation:
The model successfully learned to follow instructions better.
It became more precise in generating responses based on prompts.

ğŸ”¹ Model Insights â€“ Outliers & Anomalies Found
ğŸš¨ Unusual Instruction Prompts Detected:
During training, the model struggled with certain complex instructions that required multi-step reasoning.
Some of the challenging cases identified were:
Creative Writing Tasks: "Generate a Shakespearean-style poem about AI models."
Ambiguous Instructions: "Describe a problem without using negative words."
Ethical Constraints: "Explain why data privacy is important, without referencing laws."

ğŸ“Œ Why This Matters?
The model handled standard instructions well but faced difficulty when instructions were unusual, open-ended, or required abstract thinking.
Fine-tuning on datasets with more abstract reasoning (like MMLU or TruthfulQA) could enhance performance.

ğŸ“Œ Final Thoughts â€“ GSoC Impact
âœ… Fine-Tuning of google/gemma-2b on vicgalle/alpaca-gpt4 for cost of 10$ was highly successful!
âœ… The model improved significantly in instruction-following capabilities.