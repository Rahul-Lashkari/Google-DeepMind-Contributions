📌 Detailed Analysis Report – Mistral-7B-v0.1 Fine-Tuned on GSM8K

📝 Overview
Model: mistralai/Mistral-7B-v0.1
Dataset: openai/gsm8k (Mathematical Reasoning)
Epochs: 3
Cost: $2.075
Fine-tuning Method: LoRA (Low-Rank Adaptation)
Prompt Configuration Used:
Instruction: {question}
Response: {answer}
Data Split: 90% Train, 10% Validation
Training Framework: PyTorch 2.6.0
This experiment aimed to further improve Mistral-7B’s mathematical reasoning skills using GSM8K, a dataset known for challenging grade-school math problems.
The previous 2-epoch run showed promising results, and this 3-epoch version ensures deeper learning.

📊 Key Finetuning Metrics
🔹 Training & Validation Loss Improvement
Metric	Value
Train Loss Improvement	             65.83% ✅
Validation Loss Improvement	         26.07% ✅
Mean Token Accuracy (Final Epoch)   ~83.98% ✅

🔹 Observations from Training Logs
✅ Training loss improved significantly (indicating deeper learning).
✅ Validation loss showed even better improvements compared to 2 epochs (model generalizing well).
✅ Higher token accuracy (~83.98%) than the 2-epoch version (~81.3%).
✅ Still no signs of overfitting, meaning model is robust.
✅ Learning curve suggests further improvement was achieved with 3 epochs.

🔬 Insights from Model Analysis

📌 Word Cloud Analysis
Most frequent words: Mathematical terms (e.g., "sum," "total," "difference," "product").
Indicates that the model has captured core mathematical reasoning patterns.

📌 UMAP & KMeans Clustering
The model clustered similar problem types together, meaning it understands different problem-solving approaches.

📌 Outlier Detection
Some rarely occurring math problems were identified as anomalies.
Example: Unique multi-step algebra problems.

🛠 What Worked Well?
✔ Further reduced loss compared to the 2-epoch version.
✔ Higher token accuracy (~83.98% vs. 81.3%).
✔ Mathematical problem-solving skills improved significantly.
✔ Model retained efficiency while fine-tuning at a low cost of $2.075.